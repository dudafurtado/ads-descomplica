1. O que é front-end, back-end e persistência de dados?
Vamos entender a segregação de responsabilidade de um software completo.

1. Back-end

O back-end é a camada responsável pela lógica de negócios, processamento e integração 
com serviços externos e persistência.

Características técnicas

Camada de aplicação: Onde ficam as regras de negócio, validações e orquestração de processos.
Serviços de API: Disponibiliza endpoints (ex.: REST, GraphQL, gRPC) para o front-end ou 
outros sistemas consumirem.
Controle de segurança: Autenticação, autorização, criptografia e auditoria.
Gerenciamento de estado: Mantém sessões, filas, cache e comunicação com bancos de dados.

Tecnologias comuns

Linguagens: Python (Django, FastAPI), Java (Spring Boot), JavaScript/TypeScript 
(Node.js, NestJS), Go, C#.

Arquiteturas:

Monolito: tudo em uma única aplicação.
Microsserviços: vários serviços pequenos, independentes e escaláveis.
Serverless: funções isoladas, executadas sob demanda.

Processo típico

Recebe uma requisição do front-end via HTTP/HTTPS.
Processa dados, aplica regras de negócio.
Persiste informações em banco de dados ou consome APIs externas.
Retorna resposta (JSON, XML, etc.) para o front-end.

2. Front-end

O front-end é a camada que interage diretamente com o usuário final, seja via Web, 
Mobile ou Desktop.

Características técnicas

Renderização de UI: HTML, CSS, JavaScript → definem estrutura, estilo e comportamento.
Interação com o back-end: Consome APIs para buscar dados dinâmicos.
Gerenciamento de estado no cliente: Redux, Context API, Zustand ou hooks nativos.

SPAs e PWAs:

SPA (Single Page Application): a página não recarrega ao navegar; frameworks como React, 
Angular e Vue são comuns.
PWA (Progressive Web App): apps web com comportamento parecido com nativos (offline, 
push notifications).

Fluxo técnico

O usuário interage com a UI → gera evento (clique, envio de formulário).
O front-end chama a API no back-end.
Recebe os dados (JSON) e renderiza dinamicamente.

3. Persistência de Dados

A persistência garante que os dados sejam armazenados de forma durável, mesmo 
após falhas ou desligamento do sistema.

Conceitos-chave

Modelo ACID (Atomicidade, Consistência, Isolamento, Durabilidade) → garante 
integridade em bancos relacionais.
Transações → sequência de operações atômicas; se falhar, desfaz tudo (rollback).

Sistemas de Armazenamento:

Relacionais (SQL): MySQL, PostgreSQL, Oracle, SQL Server.
Não Relacionais (NoSQL): MongoDB (documentos), Redis (chave-valor), Cassandra (colunas).

Camadas de acesso:

Drivers nativos (ex.: JDBC, psycopg2).
ORMs (Object-Relational Mapping): Sequelize, SQLAlchemy, Hibernate → convertem objetos 
para tabelas.

Fluxo técnico

O back-end recebe uma requisição para salvar/consultar dados.
Um repositório ou DAO (Data Access Object) traduz isso em comandos SQL/NoSQL.
O banco persiste de forma transacional e retorna confirmação.

2. Exemplo rápido de front-end
Vamos ver na prática o que é esse tal de front-end.

1. Git – Sistema de Controle de Versão Distribuído
Definição técnica

O Git é um DVCS (Distributed Version Control System) criado por Linus Torvalds em 2005, 
projetado para:

Rastrear histórico de alterações de código-fonte.
Permitir desenvolvimento colaborativo.
Trabalhar offline (cada repositório é uma cópia completa, com histórico e metadados).

Conceitos-chave

Commits → "fotografias" do estado do código em um momento específico.
Branches → ramificações independentes para desenvolvimento paralelo.
Merge → integração de branches (pode gerar conflitos).
Rebase → reorganização de commits para histórico linear.
Tags → marcadores para versões estáveis (ex.: v1.0.0).
Remotes → repositórios externos (ex.: GitHub, GitLab).

Arquitetura

Repositório local → .git contém histórico completo.
Repositório remoto → sincronização via push/pull.

Modelos de fluxo:

Git Flow (branch develop, feature/*, release/*)
Trunk-Based Development (branch única + feature flags)
GitHub Flow (branch main + PRs)

Por que é usado em nível corporativo

Colaboração global: times distribuídos no mundo inteiro.
Integração com CI/CD: pipelines automáticas de build/test/deploy.
Rastreabilidade e auditoria: histórico completo para compliance.
Resiliência: qualquer cópia é um backup completo.

2. Node.js LTS – Plataforma de Execução JavaScript Server-Side
Definição técnica

O Node.js é um runtime baseado no motor V8 do Chrome que permite executar JavaScript 
no lado do servidor, com foco em:

Event Loop assíncrono → operações não bloqueantes.
Modelo Single-Threaded → escalabilidade via I/O assíncrono em vez de múltiplas threads.

Conceitos-chave

LTS (Long Term Support) → versões estáveis, mantidas por 30+ meses, recomendadas para produção.
NPM/Yarn/PNPM → gerenciadores de pacotes para dependências e bibliotecas.
CommonJS vs ES Modules → padrões de modularização (require vs import).
Event-driven Architecture → ideal para APIs e sistemas com alta concorrência.

Componentes Internos

Libuv: camada de abstração de I/O e event loop.
V8 Engine: compilador JIT que transforma JS em código de máquina nativo.
Bindings C/C++: permite integrações com bibliotecas nativas.

Ecossistema

Frameworks Web: Express.js, NestJS, Fastify.
APIs Reativas: RxJS, WebSockets.
Ferramentas DevOps: CLI para scripts de build, pipelines, automações.

Por que empresas usam Node.js

Alto throughput → lida bem com milhares de conexões simultâneas.
Fullstack JS → front-end (React, Vue, Angular) + back-end (Node).
Ecosistema enorme → milhares de pacotes NPM.
Microserviços e Serverless → fácil integração com nuvens (AWS Lambda, Azure Functions).

3. VSCode – IDE Leve e Extensível
Definição técnica

O Visual Studio Code é um editor de código-fonte multiplataforma, desenvolvido pela Microsoft, 
baseado no Electron (Node.js + Chromium), com arquitetura modular e suporte a extensões.

Conceitos-chave

Extensões: suporte a linguagens (Python, C#, Go), linters, debuggers.
LSP (Language Server Protocol): desacopla a inteligência da linguagem do editor → autocompletar, 
linting, refatoração.
Debugging integrado: breakpoints, inspeção de variáveis, profiling.
Terminais embutidos: execução de comandos sem sair do editor.
Remote Development: integrações com Docker, WSL e SSH.

Arquitetura interna

Frontend (UI) em HTML/CSS/JS rodando no Chromium.
Backend em Node.js para execução de tarefas e extensões.
Extensions Host → ambiente isolado para rodar extensões sem travar o editor principal.

Por que é padrão de mercado

Performance: abre rápido e suporta projetos grandes.
Flexibilidade: desde scripts simples até sistemas corporativos complexos.
Integração DevOps: Git embutido, Docker, Kubernetes, CI/CD.
Comunidade: marketplace com milhares de extensões.

[Exemplo de código]<https://github.com/FaculdadeDescomplica/tecnologias_inovadoras_-de_desenvolvimento_de_sistemas>
cicd_frontend > reactsite

3. Integrações com API
Vamos ver na prática como funciona a comunicação com uma API.

1. Postman – Plataforma para APIs

O Postman é uma plataforma completa para desenvolvimento, teste e documentação de APIs, 
muito usada por desenvolvedores, QA e equipes DevOps.

Principais recursos técnicos

Workspace colaborativo → coleções de requisições podem ser versionadas (Git), compartilhadas 
e documentadas.
Env Vars & Environments → variáveis para endpoints, tokens e configurações por ambiente 
(dev, staging, prod).
Automação e testes → scripts em JavaScript podem validar respostas (ex.: status 200, campos 
obrigatórios).
Mock Servers → simulação de endpoints antes do backend real existir.
Monitoramento → execução periódica de coleções para verificar disponibilidade.
Collections → agrupamento de requisições com organização e versionamento.

Postman não é só "ferramenta de teste manual":
Em pipelines CI/CD, é comum integrar coleções Postman para testes automatizados de APIs.

2. Respostas em JSON e Estrutura de Dados

A maioria das APIs modernas retorna dados no formato JSON (JavaScript Object Notation), pois é:

Leve
Legível por humanos
Interpretado nativamente em JavaScript e fácil de manipular em quase todas as linguagens
Estrutura técnica

Um objeto JSON é formado por:

Atributo (chave) → nome do campo.
Valor → dado associado à chave.

Boas práticas em APIs corporativas

Padronização → nomes em inglês, snake_case ou camelCase consistentes.
Versionamento → api/v1/users evita quebrar clientes quando o JSON muda.
HATEOAS → hiperlinks dentro do JSON para navegação de recursos em APIs RESTful.

3. Verbos HTTP – GET, POST, PUT, DELETE

Estes métodos HTTP seguem a semântica do protocolo REST para manipulação de recursos.

| Verbo      | Operação CRUD       | Idempotência | Descrição técnica                                             | Exemplo REST Endpoint         |
| ---------- | ------------------- | ------------ | ------------------------------------------------------------- | ----------------------------- |
| **GET**    | Read (Consulta)     | Sim          | Retorna representação do recurso. **Sem efeitos colaterais**. | `GET /api/v1/clientes`        |
| **POST**   | Create (Criação)    | Não          | Cria novo recurso. Pode retornar `201 Created`.               | `POST /api/v1/clientes`       |
| **PUT**    | Update (Substituir) | Sim          | Atualiza recurso inteiro, sobrescrevendo os dados.            | `PUT /api/v1/clientes/101`    |
| **PATCH**  | Update Parcial      | Não          | Atualiza **parte** dos campos do recurso.                     | `PATCH /api/v1/clientes/101`  |
| **DELETE** | Delete (Remover)    | Sim          | Remove recurso. Retorna `204 No Content` normalmente.         | `DELETE /api/v1/clientes/101` |

Idempotência → significa que várias chamadas têm o mesmo efeito.
DELETE /101 → apagar 1x ou 10x gera o mesmo estado: recurso removido.
POST não é idempotente: cada chamada pode criar um novo recurso.

4. Ciclo de vida típico com Postman + JSON + Verbos HTTP

Definir endpoint → URL + verbo HTTP (ex.: POST /api/v1/users).
Enviar request → corpo da requisição (body) geralmente em JSON para POST/PUT.
Receber resposta → payload em JSON + código HTTP (200, 201, 404, etc.).
Testar automaticamente → scripts Postman validam campos, tipos e status.
Automatizar em pipeline → coleções Postman rodando no CI/CD (ex.: Newman CLI).

4. Exemplo rápido de back-end: API
Vamos ver na prática o que é esse tal de back-end.

1. Eclipse: o que é e quando usar

Eclipse IDE é um ambiente de desenvolvimento modular (arquitetura OSGi) com ecossistema 
enorme de plugins. Para Spring, use o Spring Tools 4 for Eclipse (STS4), que adiciona:

criação/importação de projetos Spring (Maven/Gradle),
content assist para application.properties/.yaml
Run As → Spring Boot App,
integração com Spring Boot DevTools e LiveReload,
Spring Boot Dashboard (start/stop, perfis, variáveis, endpoints Actuator).
PS: IntelliJ é muito popular para Spring, mas Eclipse+STS4 funciona muito bem — 
especialmente se você já está no ecossistema Eclipse.

2. Pré-requisitos (macOS/Windows/Linux)

JDK LTS (recomendado Java 17 LTS).
macOS (Homebrew): brew install temurin17
Verifique: java -version
Maven (ou use o wrapper do projeto: ./mvnw)
Eclipse IDE + Spring Tools 4
Baixe a distribuição “Eclipse IDE for Enterprise Java and Web Developers” e instale o 
Spring Tools 4 via Marketplace, ou baixe a distro Spring Tools 4 (for Eclipse) já pronta.
(Opcional) Gradle (ou ./gradlew do projeto)
Configure o JAVA_HOME para o JDK correto. No Eclipse: Preferences → Java → Installed JREs 
e selecione o JDK 17, não o JRE.

3. Criar um projeto Spring Boot no Eclipse

Com o STS4 instalado:

File → New → Spring Starter Project

Selecione:

Type: Maven (ou Gradle)
Boot version: estável (ex.: 3.x)
Packaging: jar (ou war)
Java: 17
Adicione starters: spring-web, spring-boot-devtools, spring-data-jpa, postgresql (exemplo), 
etc.
Concluir.

Estrutura gerada (Maven):

src/main/java/.../Application.java        // @SpringBootApplication
src/main/resources/application.properties // config
pom.xml                                   // dependências


Classe main (gerada):

@SpringBootApplication
public class Application {
  public static void main(String[] args) {
    SpringApplication.run(Application.class, args);
  }
}

4. Importar um projeto existente (Maven/Gradle)

Maven: File → Import → Existing Maven Projects → aponte para a pasta com pom.xml.
Gradle: File → Import → Existing Gradle Project.

Aguarde o index/build e o download das dependências.

Se o Java compliance do projeto não bater (ex.: projeto em 17 e workspace em 11):
Project → Properties → Java Compiler (mude para 17) e em Project Facets ajuste “Java 17”.

5. Como rodar (run/debug)
Pelo Eclipse

Run: clique direito no projeto → Run As → Spring Boot App (ou Java Application se 
não tiver STS).
Debug: Debug As → Spring Boot App (breakpoints, hot code replace).
Perfis e env vars: Run Configurations → Spring Boot App
Arguments: --spring.profiles.active=dev
Environment: SPRING_DATASOURCE_URL=...

Pelo terminal (útil no CI/CD)
./mvnw spring-boot:run
# ou
./mvnw clean package && java -jar target/app-0.0.1-SNAPSHOT.jar
# Gradle
./gradlew bootRun

6. Configuração e perfis

application.properties / application.yml:

server.port=8080
spring.datasource.url=jdbc:postgresql://localhost:5432/minha_base
spring.datasource.username=app
spring.datasource.password=senha
spring.jpa.hibernate.ddl-auto=validate

Perfis (dev/prod):

application-dev.yml
application-prod.yml

Ative com --spring.profiles.active=dev ou variável SPRING_PROFILES_ACTIVE=dev.

7. DevTools & LiveReload (desenvolvimento rápido)

Adicione spring-boot-devtools (escopo runtime).
Em desenvolvimento, alterações em classes/recursos reiniciam o context automaticamente.
Com STS4 + LiveReload, o browser atualiza após recompilações (para front simples).
Hot swap em métodos grandes ou mudanças de assinatura exigem restart do Boot (o DevTools cuida disso).

8. Logs e Actuator

Logs: configure logging.level:

logging.level.org.springframework.web=INFO
logging.level.com.seu.pacote=DEBUG

Actuator: adicione starter spring-boot-starter-actuator:

management.endpoints.web.exposure.include=health,info,metrics,env

Acesse /actuator/health, /actuator/metrics.

9. Testes

Unitários: JUnit 5 + Mockito.

Slice tests: @WebMvcTest, @DataJpaTest.

Integração: @SpringBootTest (sobe o contexto real).

@SpringBootTest
class ApplicationTests {
  @Test void contextLoads() {}
}

Rode com Run As → JUnit Test ou ./mvnw test.

10. Erros comuns & troubleshooting

Porta ocupada (EmbeddedServletContainerException):
Altere server.port=8081 ou mate o processo que segura a porta.

Dependências quebradas:

Maven: Project → Update Project (Alt+F5) / ./mvnw -U clean install.
Gradle: Gradle → Refresh Gradle Project / ./gradlew clean build.

JDK incompatível:

Garanta JDK 17 no workspace e no project (Installed JREs + Compiler level).
Classpath duplicado / conflito de starters:
Evite trazer servidores embutidos duplos (ex.: spring-boot-starter-tomcat + Jetty junto).

Encoding/Locale:

Configure -Dfile.encoding=UTF-8 em Run Configurations se necessário.

11. Pipeline básica (integração com Eclipse)

Mesmo usando Eclipse, configure build por linha de comando (o que o CI fará):

# Exemplo GitLab CI (resumo)
image: maven:3.9-eclipse-temurin-17
stages: [build, test, package]
cache: { paths: [ .m2/repository ] }

build:
  stage: build
  script: [ "./mvnw -B -U -DskipTests clean package" ]

test:
  stage: test
  script: [ "./mvnw test" ]

package:
  stage: package
  script: [ "java -jar target/app-*.jar --spring.profiles.active=test" ]


Assim você garante que o que roda no Eclipse também roda no CI/servidor.

5. Acessando banco de dados
Vamos ver na prática como acessar o banco de dados pela nossa API.

Como a API acessa o banco de dados na prática

Quando falamos em “acessar o banco pela API”, estamos descrevendo o fluxo que 
ocorre entre uma requisição HTTP e a execução de operações no banco (consultas, inserções, 
atualizações, exclusões) de forma segura, performática e transacional.

Esse processo normalmente acontece em camadas bem definidas:

Rota e Controlador

A API expõe endpoints (por exemplo, /api/v1/clientes).

Cada endpoint mapeia um verbo HTTP (GET, POST, PUT, DELETE) para uma operação.

Quando o cliente chama esse endpoint, a API recebe os dados de entrada (parâmetros, 
corpo da requisição) e os envia para a camada de serviço.

Camada de Serviço (Regras de Negócio)

Aqui ficam as validações, regras de negócio e orquestração.

Antes de falar com o banco, a API garante que os dados estão corretos, que o usuário 
tem permissão e que as transações fazem sentido para o domínio da aplicação.

Camada de Persistência

Esta é a parte responsável por conversar diretamente com o banco de dados.

Normalmente usamos drivers (bibliotecas nativas) ou ORMs (Object-Relational Mappers) que 
abstraem o SQL e ajudam a gerar comandos seguros e eficientes.

Todas as consultas usam parametrização para evitar SQL Injection e podem estar dentro de 
transações para garantir consistência.

Conexão e Pooling

A aplicação não cria uma conexão nova para cada requisição. Em vez disso, mantém um pool 
de conexões abertas e as reutiliza para melhorar desempenho.

Esse pool é gerenciado pelo framework ou biblioteca de acesso ao banco.

Resposta ao Cliente

Após executar a consulta, a API retorna uma resposta estruturada, geralmente em JSON, 
com códigos HTTP adequados (200 OK, 201 Created, 404 Not Found, 500 Internal Server Error).

Boas práticas envolvidas

Migrations: manter a evolução do esquema do banco versionada.

Transações: operações múltiplas devem ser atômicas — tudo ou nada.

Paginação e filtros: essencial para consultas em grandes volumes.

Monitoramento e métricas: acompanhar latência, conexões ativas, queries lentas.

Segurança: senhas e chaves nunca ficam no código, mas em variáveis de ambiente ou serviços 
de segredos.

Escalabilidade: uso de índices, replicação e cache quando necessário.

6. Front-end acessando o nosso back-end
Vamos ver na prática como o front-end e o back-end se conversam.

Resumo: 

No desenvolvimento de aplicações web, a arquitetura em camadas, também conhecida como 
n-tier architecture, é um modelo amplamente utilizado que organiza os componentes de um 
sistema em camadas distintas, cada uma com responsabilidades específicas. Essa abordagem 
oferece diversas vantagens, como a separação de responsabilidades, a reutilização de código 
e a maior facilidade de manutenção.

Em uma arquitetura em camadas típica, temos três camadas principais: apresentação, domínio 
e dados. A camada de apresentação, representada pelo front-end, é responsável pela interface 
com o usuário, ou seja, é a parte visual da aplicação com a qual o usuário interage, como 
um site ou aplicativo mobile. É nessa camada que são tratados os elementos visuais, a 
interação do usuário e a navegação.

A camada de domínio, por sua vez, representa o back-end e abriga as regras de negócio, a 
lógica da aplicação e o processamento das informações. É nessa camada que os dados recebidos 
do front-end são processados, validados e utilizados para realizar as operações necessárias. 
O back-end atua como um intermediário entre o front-end e a camada de dados, garantindo a 
integridade e a segurança das informações.

A camada de dados, como o próprio nome sugere, é responsável por persistir os dados da 
aplicação, geralmente em um banco de dados. É nessa camada que são realizadas as operações 
de leitura, escrita, atualização e exclusão de dados. A camada de dados deve ser projetada 
para garantir a integridade, a consistência e a segurança dos dados armazenados.

A comunicação entre as camadas é fundamental para o funcionamento da aplicação. O front-end 
se comunica com o back-end por meio de APIs (Application Programming Interfaces), que 
definem um conjunto de regras e especificações que permitem a comunicação entre diferentes 
sistemas. O back-end, por sua vez, se comunica com a camada de dados utilizando bibliotecas 
e frameworks específicos para cada tipo de banco de dados.

Com a evolução da arquitetura de software, o modelo de microserviços surgiu como uma 
alternativa para lidar com a crescente complexidade das aplicações. Diferentemente da 
arquitetura monolítica, em que todos os componentes da aplicação estão interligados em um 
único bloco, os microserviços permitem dividir a aplicação em serviços menores, 
independentes e autônomos.

Essa abordagem traz diversas vantagens, como a possibilidade de utilizar diferentes 
tecnologias e linguagens de programação em cada serviço, a escalabilidade independente 
de cada serviço, a maior facilidade de manutenção e a tolerância a falhas. Cada microserviço 
é responsável por uma funcionalidade específica da aplicação e se comunica com outros 
microserviços por meio de APIs.

A segurança é um aspecto crucial em qualquer aplicação, especialmente em arquiteturas em 
camadas e microserviços. É fundamental garantir que a comunicação entre as camadas seja 
segura, utilizando mecanismos como autenticação, autorização e criptografia. Além disso, 
é importante proteger a camada de dados contra acessos não autorizados, utilizando 
firewalls, senhas fortes e outros mecanismos de segurança.

Em resumo, a arquitetura em camadas e os microserviços são modelos de desenvolvimento de 
software que oferecem diversas vantagens em termos de organização, escalabilidade, 
manutenção e segurança. A escolha do modelo mais adequado depende das necessidades 
específicas de cada aplicação, mas é fundamental compreender os princípios e as 
características de cada abordagem para tomar a decisão mais acertada.